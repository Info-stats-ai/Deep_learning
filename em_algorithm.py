{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNstu9NSRxK0IOuKyyLSpHv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"9aeQyIWX4cJU"},"outputs":[],"source":["import numpy as np\n","from scipy.sparse import load_npz\n","from sklearn.cluster import KMeans\n","import os\n","\n","X = load_npz(\"processed/tfidf_matrix.npz\")\n","N, D = X.shape\n","K = 5\n","\n","# Initialization using KMeans\n","kmeans = KMeans(n_clusters=K, random_state=42)\n","kmeans.fit(X)\n","\n","means = kmeans.cluster_centers_\n","labels = kmeans.labels_\n","weights = np.array([np.sum(labels == k) for k in range(K)]) / N\n","\n","covariances = []\n","for k in range(K):\n","    idx = np.where(labels == k)[0]\n","    cluster_data = X[idx]\n","    mean_k = means[k]\n","    ex2 = cluster_data.multiply(cluster_data).mean(axis=0)\n","    var_k = np.asarray(ex2).flatten() - mean_k**2\n","    var_k[var_k < 1e-8] = 1e-8\n","    covariances.append(var_k)\n","covariances = np.array(covariances)\n","\n","# EM loop\n","def log_gaussian(x, mean, var):\n","    eps = 1e-8\n","    return -0.5 * np.sum(np.log(2 * np.pi * var + eps)) - 0.5 * np.sum(((x - mean)**2) / (var + eps))\n","\n","log_likelihoods = []\n","max_iter = 30\n","threshold = 1e-4\n","\n","X_dense = X.toarray()\n","for iter in range(max_iter):\n","    # E-step\n","    resp = np.zeros((N, K))\n","    for k in range(K):\n","        log_p = np.log(weights[k] + 1e-8) + np.array([log_gaussian(x, means[k], covariances[k]) for x in X_dense])\n","        resp[:, k] = log_p\n","    max_log = np.max(resp, axis=1, keepdims=True)\n","    resp = np.exp(resp - max_log)\n","    resp = resp / np.sum(resp, axis=1, keepdims=True)\n","\n","    # M-step\n","    Nk = np.sum(resp, axis=0)\n","    weights = Nk / N\n","    for k in range(K):\n","        means[k] = np.sum(resp[:, k].reshape(-1, 1) * X_dense, axis=0) / Nk[k]\n","        diff = X_dense - means[k]\n","        cov = np.sum(resp[:, k].reshape(-1, 1) * (diff ** 2), axis=0) / Nk[k]\n","        cov[cov < 1e-8] = 1e-8\n","        covariances[k] = cov\n","\n","    # Log-likelihood\n","    ll = 0\n","    for i in range(N):\n","        ll += np.log(np.sum([weights[k] * np.exp(log_gaussian(X_dense[i], means[k], covariances[k])) for k in range(K)]))\n","    log_likelihoods.append(ll)\n","    if iter > 0 and abs(log_likelihoods[-1] - log_likelihoods[-2]) < threshold:\n","        break\n","\n","# Save\n","os.makedirs(\"em_output\", exist_ok=True)\n","np.save(\"em_output/em_means.npy\", means)\n","np.save(\"em_output/em_covariances.npy\", covariances)\n","np.save(\"em_output/em_weights.npy\", weights)\n","np.save(\"em_output/em_log_likelihoods.npy\", log_likelihoods)\n"]}]}