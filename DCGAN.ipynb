{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN0tbR2PBNG20+lwMiyV6kN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yudm7NhAplHQ","executionInfo":{"status":"ok","timestamp":1735245146605,"user_tz":300,"elapsed":11539,"user":{"displayName":"Omkar N Thakur (Om)","userId":"12104069772117460097"}},"outputId":"4bfb3260-695d-46ed-cc59-31e5814191bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}],"source":["from keras.datasets import mnist\n","\n","from keras.models import Sequential\n","from keras.layers import *\n","from keras.optimizers import Adam\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()"]},{"cell_type":"code","source":["print(x_train.shape)\n","print(y_train.shape)\n","print(x_test.shape)\n","print(y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y8vgUBC-q2fU","executionInfo":{"status":"ok","timestamp":1735245159269,"user_tz":300,"elapsed":98,"user":{"displayName":"Omkar N Thakur (Om)","userId":"12104069772117460097"}},"outputId":"c3f03e2e-35e1-4e8f-9133-5d0846098c23"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["(60000, 28, 28)\n","(60000,)\n","(10000, 28, 28)\n","(10000,)\n"]}]},{"cell_type":"code","source":["x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n","x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"],"metadata":{"id":"I19lmuK1q89s","executionInfo":{"status":"ok","timestamp":1735245185737,"user_tz":300,"elapsed":101,"user":{"displayName":"Omkar N Thakur (Om)","userId":"12104069772117460097"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["x_train = (x_train.astype('float32')- 127.5)/127.5\n","x_test = (x_test.astype('float32')- 127.5)/127.5"],"metadata":{"id":"rGKgGtQMrEH3","executionInfo":{"status":"ok","timestamp":1735245263919,"user_tz":300,"elapsed":180,"user":{"displayName":"Omkar N Thakur (Om)","userId":"12104069772117460097"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["print(np.max(x_train))\n","print(np.min(x_train))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HACu7Mr3rXLt","executionInfo":{"status":"ok","timestamp":1735245296552,"user_tz":300,"elapsed":101,"user":{"displayName":"Omkar N Thakur (Om)","userId":"12104069772117460097"}},"outputId":"fdb6a153-9c35-4974-d354-98e3eb9035f7"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["1.0\n","-1.0\n"]}]},{"cell_type":"code","source":["num_epochs = 50\n","batch_size = 256\n","no_of_batches = math.ceil(x_train.shape[0]/batch_size)\n","half_batch = math.ceil(batch_size/2)\n","noise_dim = 100\n","# Use these Adam params for GAN's\n","adam = Adam(learning_rate=0.0002, beta_1=0.5)"],"metadata":{"id":"yfsr3s83rfLZ","executionInfo":{"status":"ok","timestamp":1735245410360,"user_tz":300,"elapsed":77,"user":{"displayName":"Omkar N Thakur (Om)","userId":"12104069772117460097"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# define the generator\n","generator = Sequential()\n","generator.add(Dense(7*7*128, input_dim=noise_dim))#densed step1\n","generator.add(Reshape((7,7,128)))#reshaped\n","generator.add(LeakyReLU(0.2)) #adding non linearity\n","generator.add(BatchNormalization())\n","#step 2 : Upsample , into 14*14*64\n","generator.add(UpSampling2D())\n","generator.add(Conv2Dcr(64, kernel_size=(5,5), padding='same'))\n","generator.add(LeakyReLU(0.2))\n","generator.add(BatchNormalization())\n","#step 3 : Upsample , into 28*28*1\n","generator.add(UpSampling2D())\n","generator.add(Conv2D(1, kernel_size=(5,5), padding='same', activation='tanh'))\n","generator.compile(loss='binary_crossentropy', optimizer=adam)\n","generator.summary()\n","\n","# Define the Discriminator Model\n","discriminator = Sequential()\n","discriminator.add(Conv2D(64, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=(28,28,1)))\n","discriminator.add(LeakyReLU(0.2))\n","\n","# Next Conv layer (14*14*64) to 7*7*128\n","discriminator.add(Conv2D(128, kernel_size=(5,5), strides=(2,2), padding='same'))\n","discriminator.add(LeakyReLU(0.2))\n","\n","# Flatten the output\n","discriminator.add(Flatten())\n","discriminator.add(Dense(1, activation='sigmoid'))\n","discriminator.compile(loss='binary_crossentropy', optimizer=adam)\n","discriminator.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":900},"id":"IwbxWto5r340","executionInfo":{"status":"ok","timestamp":1735246495443,"user_tz":300,"elapsed":307,"user":{"displayName":"Omkar N Thakur (Om)","userId":"12104069772117460097"}},"outputId":"4349d681-cadd-4eba-d340-c5832f179742"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_2\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6272\u001b[0m)                │         \u001b[38;5;34m633,472\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ up_sampling2d_2 (\u001b[38;5;33mUpSampling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_transpose_2 (\u001b[38;5;33mConv2DTranspose\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m204,864\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ up_sampling2d_3 (\u001b[38;5;33mUpSampling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_transpose_3 (\u001b[38;5;33mConv2DTranspose\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │           \u001b[38;5;34m1,601\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6272</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">633,472</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ up_sampling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_transpose_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">204,864</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ up_sampling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_transpose_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,601</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m840,705\u001b[0m (3.21 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">840,705</span> (3.21 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m840,321\u001b[0m (3.21 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">840,321</span> (3.21 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_3\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │           \u001b[38;5;34m1,664\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m204,928\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6272\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │           \u001b[38;5;34m6,273\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6272</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,273</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m212,865\u001b[0m (831.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">212,865</span> (831.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m212,865\u001b[0m (831.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">212,865</span> (831.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"pYLeOWxzwnrD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Dx58ttKWwnoG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tQfgck2awnkg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OevOpDtlwnfO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Ih___ZUVwnXW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7ow6Rdw9wnMl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The line `generator.add(BatchNormalization())` refers to adding a Batch Normalization layer to a neural network generator model, typically in the context of a Generative Adversarial Network (GAN). Batch Normalization is a technique used to improve the training stability and performance of deep neural networks.\n","\n","## Purpose of Batch Normalization\n","\n","Batch Normalization serves several important purposes in neural networks:\n","\n","1. **Mitigating Internal Covariate Shift**: It normalizes the inputs to each layer, reducing the internal covariate shift problem where the distribution of each layer's inputs changes during training[1].\n","\n","2. **Faster Training**: By stabilizing the input distribution, it allows for faster convergence during the training process[5].\n","\n","3. **Higher Learning Rates**: Batch Normalization enables the use of higher learning rates without the risk of divergence, further accelerating training[5].\n","\n","4. **Regularization Effect**: It introduces a slight regularization effect, potentially reducing the need for other regularization techniques like dropout[6].\n","\n","5. **Improved Gradient Flow**: It helps in maintaining a more stable gradient flow through the network, mitigating issues like vanishing or exploding gradients[1].\n","\n","## Implementation in GANs\n","\n","In the context of a GAN's generator:\n","\n","1. **Stabilizing Training**: GANs are notoriously difficult to train, and Batch Normalization can help stabilize the training process[7].\n","\n","2. **Normalizing Feature Distributions**: It ensures that the generator's intermediate layers produce features with consistent distributions, which can be crucial for generating high-quality outputs[3].\n","\n","3. **Improved Learning**: By normalizing the inputs to each layer, it allows the generator to learn more effectively across its entire depth[2].\n","\n","## How It Works\n","\n","When you add `BatchNormalization()` to your generator:\n","\n","1. It normalizes the output of the previous layer by subtracting the batch mean and dividing by the batch standard deviation[1].\n","\n","2. It then scales and shifts the normalized values using learned parameters (gamma and beta)[1].\n","\n","3. This process is applied to each mini-batch during training, helping to maintain a consistent distribution of activations throughout the network[3].\n","\n","By incorporating Batch Normalization, you're essentially giving your generator model a tool to self-regulate its internal representations, leading to more stable and efficient training, especially in the complex and often unstable environment of GAN training[7].\n","\n","Citations:\n","[1] https://en.wikipedia.org/wiki/Batch_normalization\n","[2] https://towardsdatascience.com/batch-norm-explained-visually-how-it-works-and-why-neural-networks-need-it-b18919692739?gi=f4d3c2a40966\n","[3] https://viso.ai/deep-learning/batch-normalization/\n","[4] https://github.com/christianversloot/machine-learning-articles/blob/main/batch-normalization-with-pytorch.md\n","[5] https://towardsdatascience.com/batch-normalization-8a2e585775c9\n","[6] https://www.geeksforgeeks.org/what-is-batch-normalization-in-deep-learning/\n","[7] https://stackoverflow.com/questions/58315023/gan-with-batch-norm-acting-very-weird-both-discriminator-and-generator-get-zero\n","[8] https://www.reddit.com/r/MachineLearning/comments/ql5hdb/d_why_do_we_apply_batch_normalization_between/"],"metadata":{"id":"p6y5YSZftPHQ"}},{"cell_type":"markdown","source":["The mathematics behind batch normalization (BN) is designed to normalize the inputs to each layer in a neural network, reducing internal covariate shift and improving training stability. Let's break down the key mathematical components of batch normalization:\n","\n","## Normalization Step\n","\n","For a given mini-batch B of size m, and a particular feature k, the normalization is performed as follows:\n","\n","1. **Mini-batch mean:**\n","   $$ \\mu_B^{(k)} = \\frac{1}{m} \\sum_{i=1}^m x_i^{(k)} $$\n","\n","2. **Mini-batch variance:**\n","   $$ (\\sigma_B^{(k)})^2 = \\frac{1}{m} \\sum_{i=1}^m (x_i^{(k)} - \\mu_B^{(k)})^2 $$\n","\n","3. **Normalized value:**\n","   $$ \\hat{x}_i^{(k)} = \\frac{x_i^{(k)} - \\mu_B^{(k)}}{\\sqrt{(\\sigma_B^{(k)})^2 + \\epsilon}} $$\n","\n","   Where ε is a small constant added for numerical stability[1][3].\n","\n","## Scaling and Shifting\n","\n","After normalization, BN applies a learnable scale and shift:\n","\n","$$ y_i^{(k)} = \\gamma^{(k)} \\hat{x}_i^{(k)} + \\beta^{(k)} $$\n","\n","Where γ^(k) and β^(k) are learnable parameters[2][3].\n","\n","## Inference Phase\n","\n","During inference, BN uses running statistics:\n","\n","1. **Running mean:**\n","   $$ E[x^{(k)}] = \\frac{1}{j} \\sum_{i=1}^j \\mu_B^{(k)} $$\n","\n","2. **Running variance:**\n","   $$ Var[x^{(k)}] = \\frac{1}{j} \\sum_{i=1}^j (\\sigma_B^{(k)})^2 $$\n","\n","Where j is the number of mini-batches[4].\n","\n","The inference transformation becomes:\n","\n","$$ y^{(k)} = \\gamma^{(k)} \\frac{x^{(k)} - E[x^{(k)}]}{\\sqrt{Var[x^{(k)}] + \\epsilon}} + \\beta^{(k)} $$\n","\n","## Gradient Properties\n","\n","An important property of BN is that it bounds the magnitude of the gradients:\n","\n","$$ \\|\\nabla_{y_i} \\hat{L}\\| \\leq C \\cdot \\|\\nabla_z \\hat{L}\\| $$\n","\n","Where C is a constant, and z is the layer output after BN[3].\n","\n","## Linear Transformation\n","\n","BN can be viewed as a linear transformation:\n","\n","$$ y = \\frac{\\gamma}{\\sqrt{Var_x + \\epsilon}} x + \\beta - \\frac{\\gamma E_x}{\\sqrt{Var_x + \\epsilon}} $$\n","\n","This form shows how BN scales and shifts the input[4].\n","\n","By applying these mathematical operations, batch normalization helps stabilize the distribution of layer inputs throughout training, allowing for faster convergence and the use of higher learning rates. The learnable parameters γ and β give the network the flexibility to represent the identity transform if necessary, ensuring that BN doesn't limit the network's expressive power.\n","\n","Citations:\n","[1] https://towardsdatascience.com/the-math-behind-batch-normalization-90ebbc0b1b0b\n","[2] https://www.datacamp.com/tutorial/batch-normalization-tensorflow\n","[3] https://en.wikipedia.org/wiki/Batch_normalization\n","[4] https://datascience.stackexchange.com/questions/105152/equations-in-batch-normalization-theory-and-how-to-use-it-with-tensorflow\n","[5] https://pub.towardsai.net/demystifying-batch-normalization-theory-mathematics-and-implementation-f04077298807?gi=7c7b6d77f6c2\n","[6] https://www.reddit.com/r/MachineLearning/comments/ql5hdb/d_why_do_we_apply_batch_normalization_between/\n","[7] https://towardsdatascience.com/batch-norm-explained-visually-how-it-works-and-why-neural-networks-need-it-b18919692739?gi=f4d3c2a40966"],"metadata":{"id":"QddTTEfc01ni"}},{"cell_type":"code","source":["\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uF6mdzJTsVcW","executionInfo":{"status":"ok","timestamp":1735247497013,"user_tz":300,"elapsed":259,"user":{"displayName":"Omkar N Thakur (Om)","userId":"12104069772117460097"}},"outputId":"b08e0e21-32ae-4e97-bacf-43ef2e3b1414"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":[" images   images_new   ls   models  'models!'   models_new   sample_data\n"]}]},{"cell_type":"code","source":["# define the generator\n","generator = Sequential()\n","generator.add(Dense(7*7*128, input_dim=noise_dim))#densed step1\n","generator.add(Reshape((7,7,128)))#reshaped\n","generator.add(LeakyReLU(0.2)) #adding non linearity\n","generator.add(BatchNormalization())\n","#step 2 : Upsample , into 14*14*64\n","generator.add(Conv2DTranspose(64, kernel_size=(5,5), padding='same'))\n","generator.add(LeakyReLU(0.2))\n","generator.add(BatchNormalization())\n","#step 3 : Upsample , into 28*28*1\n","\n","generator.add(Conv2DTranspose(1, kernel_size=(5,5), padding='same', activation='tanh'))\n","generator.compile(loss='binary_crossentropy', optimizer=adam)\n","generator.summary()\n","\n","# Define the Discriminator Model\n","discriminator = Sequential()\n","discriminator.add(Conv2D(64, kernel_size=(5,5), strides=(2,2), padding='same', input_shape=(28,28,1)))\n","discriminator.add(LeakyReLU(0.2))\n","\n","# Next Conv layer (14*14*64) to 7*7*128\n","discriminator.add(Conv2D(128, kernel_size=(5,5), strides=(2,2), padding='same'))\n","discriminator.add(LeakyReLU(0.2))\n","\n","# Flatten the output\n","discriminator.add(Flatten())\n","discriminator.add(Dense(1, activation='sigmoid'))\n","discriminator.compile(loss='binary_crossentropy', optimizer=adam)\n","discriminator.summary()"],"metadata":{"id":"Prl6ga_owtTJ"},"execution_count":null,"outputs":[]}]}